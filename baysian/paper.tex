\documentclass[twocolumn]{jarticle}
\title{ベイジアンネットワーク}
\author{白坂貴規}
\date{\today}
\setlength{\topmargin}{-2cm}
\setlength{\textheight}{250mm}
\usepackage[dvipdfmx]{graphicx}
\usepackage{amsmath, amssymb, bm}

%表のテンプレ
%\begin{table}[!htbp]
%  \begin{center}
%    \caption{}
%    \begin{tabular}{ccc} \hline
%    \end{tabular}
%    \label{tab:}
%  \end{center}
%\end{table}

%図のテンプレ
%\begin{figure}[!htbp]
%  \begin{center}
%    \includegraphics[width=14cm]{パス}
%    \caption{}
%    \label{fig:}
%  \end{center}
%\end{figure}

\begin{document}
\maketitle

\section{ベイズ推論の基礎}
ベイズ推論では学習や予測, モデル選択などを全て確率分布上の計算問題として取り扱う.
\subsection{確率推論}
${M}$次元ベクトル${\bm {x} = (x_1, \dots, x_M)^T \in \mathbb{R}^M}$の実数関数${p(\bm {x})}$が次の条件を満たす時, ${p(\bm {x})}$を{\bf 確率密度関数(probability density function})と呼ぶ.
\begin{eqnarray}
  p(\bm {x}) \geq 0
  \int p(\bm {x}) \, \mathrm{d}{\bm {x}} = 1
\end{eqnarray}
また, 各要素が離散値である時, ${p(\bm {x})}$を{\bf 確率質量関数(probability mass function})と呼ぶ. 以降, 確率密度関数や確率質量関数で決められる${\bm {x}}$の分布を{\bf 確率分布 (probabilistic distribution)}あるいは{\bf 確率モデル (probabilistic model)}と呼ぶ.
ある2つの変数${x}$と${y}$に関する確率分布${p(x, y)}$を{\bf 同時分布(joint distribution)}とよび,
\begin{equation}
  p(y) = \int_{}^{} p(x, y) \,\mathrm{d}x
\end{equation}
のように一方の変数${x}$を積分により除去する操作を{\bf 周辺化 (marginalization)} とよび, 結果として得られる確率分布${p(y)}$をyの{\bf 周辺分布}と呼ぶ. また, 同時分布${p(x, y)}$において, ${y}$に対して特定の値が決められた時の${x}$の確率分布を{\bf 条件付き分布 (conditional distribution)}とよび, 次のように定義する.
\begin{equation}
  p(x|y) = \frac{p(x, y)}{p(y)}
\end{equation}
条件付き分布${p(x|y)}$は${x}$の確率分布であり, ${y}$はこの分布の特性を決めるパラメータのようなものであると解釈できる.
\begin{equation}
  \int_{}^{} p(x|y) \,\mathrm{d}x = \frac{\int_{}^{} p(x, y) \,\mathrm{d}x}{p(y)} = \frac{p(y)}{p(y)} = 1
\end{equation}
であり, ${p(x, y)}$と${p(y)}$が共に非負であることも考慮すれば, 条件付き分布${p(x|y)}$は確率分布の用件を満たす.
さらに, 同時分布を考える際に重要となるのが{\bf 独立 (independence)}という概念である. 同時分布が
\begin{equation}
  p(x, y) = p(x)p(y)
\end{equation}
を満たす時, ${x}$と${y}$は独立であるという.
ある同時分布が与えられた時, そこから興味の対象となる条件付き分布や周辺分布を算出することをここでは{\bf ベイズ推論(Baysian inference)}, あるいは単に{\bf 推論(inference)}と呼ぶ.
{\bf 期待値(expectation)}は確率分布の特徴を定量的に表すことに使われる. ${\bm {x}}$をベクトルとした時に, 確率分布${p(\bm {x})}$に対して, ある関数${f(\bm {x})}$の期待値${\mathbb{E}_{p(\bm {x})} [f(\bm {x})]}$は次のように計算される.
\begin{equation}
  \mathbb{E}_{p(\bm {x})} [f(\bm {x})] = \int_{}^{} f(\bm {x}p(\bm {x})) \,\mathrm{d}{\bm x}
\end{equation}
2つの確率分布${p(\bm {x})}$及び${q(\bm {x})}$に対して次のような期待値を{\bf KLダイバージェンス(Kullback-Leibler divergence)}と呼ぶ.
\begin{eqnarray}
  D_{KL}[q(\bm {x})][p(\bm {x})] &=& - \int_{}^{} q(\bm {x}) \ln \frac{p(\bm {x})}{q(\bm {x})}  \,\mathrm{d}{\bm {x}} \nonumber \\
  &=& \mathbb{E}_{q(\bm {x})[\ln q(\bm {x})]} \nonumber \\
  &-& \mathbb{E}_{q(\bm {x})}[\ln p(\bm {x})]
\end{eqnarray}
KLダイバージェンスは任意の確率分布のくみに対して非負であり, 0となるのは2つの分布が完全に一致する場合${p(\bm {x}) = q(\bm {x})}$に限られる. また, KLダイバージェンすは2つの確率分布の"距離"を表していると解釈されるが, ${p(\bm {x})}$と${q(\bm {x})}$が対称ではない為, 数学的な距離の公理は満たしていない.

\subsection{変数変換}
既知の確率密度関数に対して変数関数を行うことで新たな確率密度関数を導出することを考える. 全単射の関数${f : \mathbb{R}^M \to \mathbb{R}^M}$によって変数を${\bm {y} = f(\bm {x})}$のように一対一に変換する操作は, 既知の確率密度関数を${p_{x}(\bm {x})}$とすれば, 変換によって得られる${\bm {y}}$の確率密度関数は
\begin{equation}
  p_y(\bm {y}) = p_x(g(\bm {y})) \left\lvert \det (J_g)\right\rvert
\end{equation}
とかける. ただし, ${J}$は${f}$の逆関数${g}$の{\bf ヤコビ行列(Jacobian matrix)}
\begin{equation}
  J_g = \left(
    \begin{array}{ccc}
      \frac{\partial x_1}{\partial y_1} & \ldots & \frac{\partial x_1}{\partial y_M} \\
      \vdots & \ddots & \vdots \\
      \frac{\partial x_M}{\partial y_1} & \ldots & \frac{\partial x_M}{\partial y_M}
    \end{array}
  \right)
\end{equation}
であり, ${\det (J_g)}$は${J_g}$の行列式である.

\subsection{グラフィカルモデル}
{\bf グラフィカルモデル(graohical model)}は, 確率モデルに存在する複数の変換の関係性をノードと矢印を使って表現する記法である. 例として, 次のようにあるパラメータ${\theta }$に依存して${N}$個の変数${\bm {X} = {x_1, \ldots, x_N}}$が発生するような確率モデルを考える. グラフィカルモデルは次図のようになる.
%\begin{figure}[!htbp]
%  \begin{center}
%    \includegraphics[width=14cm]{パス}
%    \caption{}
%    \label{fig:}
%  \end{center}
%\end{figure}
\begin{equation}
  p(\bm {X}, \theta) = p(\theta)p(\bm {X}|\theta) = p(\theta)\prod_{n=1}^N p(x_n|\theta)
\end{equation}
なお, 上式における${p(\bm {X}|\theta)}$を{\bf 尤度関数(likelihood function)}, ${p(\theta)}$をパラメータ${\theta}$の{\bf 事前分布}と呼ぶ.
\subsection{指数分布族}
ガウス分布やディクレ分布など, ベイズ推論で用いられる多くの実用的な確率分布は, {\bf 指数分布族 (exponential family)}と呼ばれるある形式をもつクラスに属する. その前に, 代表的な確率分布をいくつか紹介する.
一次元の{\bf ガウス分布 (Gaussian distribution)}または{\bf 正規分布 (normal distribution)}は次のような${x \in \mathbb{R}}$の確率密度関数をもつ分布である.
\begin{equation}
  \mathcal{N} (x|\mu, \sigma^2) = \frac{1}{\sqrt{2\pi \sigma ^2}} \exp (- \frac{(x - \mu)^2}{2\sigma^2})
\end{equation}
${\mu \in \mathbb{R}}$は平均パラメータで, ${\sigma^2 > 0}$は分散パラメータである. ガウス分布は次のように ${M}$次元の多変量に拡張される.
\begin{equation}
  \mathcal{N} (\bm {x|\mu, \sum }) = \frac{1}{\sqrt{(2\pi)^D \left\lvert \sum\right\rvert }} \exp \left(- \frac{1}{2} (\bm {x - \mu})^T {\sum_{}^{}}^{-1} (\bm {x - \mu}) \right)
\end{equation}
ここで, ${\bm {\mu} \in \mathbb{R}^M}$はM次元の平均パラメータで, ${\sum}$はサイズが${M \times M}$の{\bf 共分散行列 (covariance matrix)}である. 1次元ガウス分布の分散が正であったように, 共分散行列${\sum}$は{\bf 正定値行列 (positive definite matrix)}である必要がある.
{\bf ベルヌーイ分布 (Bernouli distribution)}はいわゆるコイン投げの分布である. 2値をとる変数${x \in \left\{0, 1\right\}}$を生成するための確率分布で, 単一のパラメータ${\mu \in (0, 1)}$によって分布の性質が決まる. 確率質量関数は
\begin{equation}
  Bern(x|\mu) = \mu^x(1 - \mu)^{1-x}
\end{equation}
と定義される.
{\bf カテゴリ分布 (categorical distribution)}は, ベルヌーイ分布を任意の${D}$値をとるように拡張したもので, ${\bm {s} \in \left\{0, 1\right\}^D}$かつ, 各要素${s_d}$が${\sum_{d=1}^D s_d = 1}$となるような確率変数${\bm {s}}$を生成する分布である.
\begin{equation}
  Cat (\bm {s} | \bm {\pi}) = \prod_{d=1}^D \pi{s_d}
\end{equation}
ここで, ${\bm {\pi} = (\pi_1, \ldots, \pi_D)^T}$は分布を決める${D}$次元のパラメータで, ${\pi_d \in (0, 1)}$かつ${\sum_{d=1}^D \pi_d = 1}$を満たすように設定する必要がある. {\bf ガンマ分布 (gamma distribution)}は正の実数${\lambda > 0}$を生成してくれるような確率分布で, 次のように定義される.
\begin{eqnarray}
  Gam(\lambda|a, b) &=& C_G(a, b)\lambda^{a-1}e^{-b\lambda} \\
  C_G (a, b) &=& \frac{{b^a}}{\Gamma (a)}
\end{eqnarray}
パラメータ${a, b}$h共に正の実数値として与える必要がある. ${\Gamma(\cdot )}$は{\bf ガンマ関数 (gamma function)}で
\begin{equation}
  \Gamma (x) = \int_{}^{} t^{x-1}e^{-t} \,\mathrm{d}t
\end{equation}
で定義される. また,
\begin{equation}
  \Gamma (x + 1) = x\Gamma(x)
\end{equation}
という性質をもつ.

\subsection{定義}
指数分布族は次のような形式でかける確率分布の族である.
\begin{equation}
  p(\bm {x}|\bm {\eta}) = h(\bm {x})\exp(\bm {\eta^T t(x)} - a(\bm {\eta}))
\end{equation}
それぞれ${\bm {\eta}}$を自然パラメータ, ${t(x)}$を十分統計量, ${h(\bm {x})}$を基底測度, ${a(\bm {x})}$を対数分配関数とよぶ. ただし,
\begin{equation}
  a(\bm {x}) = \ln \int_{}^{} h(\bm {x}) \exp(\bm {\eta^T t(x)} ) \,\mathrm{d}{\bm {x}}
\end{equation}
であり, 上式が積分して1になることを保証する.
また, ガウス分布, ポアソン分布, 多項分布, ベルヌーイ分布など多くの分布が指数分布族として表せる.
\subsection{分布の共役性}
指数分布族に対して次のような共役事前分布と呼ばれる分布族が存在する.
\begin{equation}
  p_{\lambda}(\bm {\eta}) = h_c(\bm {\eta}) \exp(\bm {\eta^T \lambda_1} - a(\eta)\lambda_2 - a_c(\bm {\lambda}))
\end{equation}
共役事前分布の重要な性質は, 次のような指数型分布族による尤度関数に対して, 事後分布も事前分布と同じような形式になることである. いま, ${N}$個のデータ${\bm {X} = {\bm {x_1}, \ldots, \bm {x_N}}}$を観測したとすると事後分布は
\begin{eqnarray}
  p(\bm {\eta | X}) &\varpropto & p_\lambda(\bm {\eta})\prod_{n=1}^{N}p(\bm {x_n|\eta}) \nonumber \\
  &=& h_c (\bm {\eta})\exp(\bm {\eta^T\lambda_1} - a(\eta)\lambda_2 - a_c(\lambda)) \nonumber \\
  && \left\{\prod_{n=1}^{N} h(\bm {x_n})\right\} \exp\left(\bm {\eta^T \sum_{n=1}^{N}}\bm {t(x_n)} - Na(\bm {\eta})\right) \nonumber \\
  &\varpropto & h_c(\bm {\eta}) \exp\left(\bm {\eta^T}  \left(\bm {\lambda_1 + \sum_{n=1}^{N}\bm{t(x_n)}}\right) - a(\bm {\eta})(\lambda_2 + N)\right)
\end{eqnarray}
となる. つまり, 事後分布のパラメータを${\bm {\hat{\lambda_1}}, \hat{\lambda_2}}$とすれば,
\begin{equation}
  \bm {\hat{\lambda_1}} = \bm {\lambda_1} + \sum_{n=1}^{N} \bm{t(x_n)}, \hat{\lambda_2} = \lambda_2 + N
\end{equation}
となっている. よって, 指数分布族による尤度関数に対して共役事前分布を用いると事前分布が解析的に求められることがわかる.
また, 共役性を利用すると事後分布を使って未観測のデータ${\bm {x_\ast }}$の予測分布を次のように求められる.
\begin{eqnarray}
  p(\bm {x_\ast|X}) &=& \int_{}^{} p(\bm {x_\ast| \eta})p(\bm {\eta|X}) \,\mathrm{d}{\bm {\eta}} \nonumber \\
  &=& \int_{}^{} h(\bm {x_\ast}) \exp(\bm {\eta^T x_\ast} - a(\bm {\eta}))h_c(\bm {\eta})\exp(\bm {\eta^T \hat{\lambda_1}} - a(\bm {\eta}) \hat{\lambda_2} - a_c(\bm {\hat{\lambda}})) \,\mathrm{d}{\bm {\eta}} \nonumber \\
  &=& h(\bm {x_\ast}) \frac{\exp(a_c(\bm {\hat{\lambda_1}} + \bm {t(x_\ast)}, \hat{\lambda_2} + 1))}{\exp(a_c(bm{\hat{\lambda_1, \hat{lambda_2}}}))}
\end{eqnarray}
結果の確率分布は一般的には指数分布族にはならない.

\subsection{逐次学習}
ベイズ推論によるモデルの学習では, 事後分布によって学習結果を保存することにより, 新規に入ってくる学習データに適応的に学習を進めることができる. これを{\bf 逐次学習 (sequential learning)}あるいは{\bf オンライン学習 (online learning)}という. 特に, 共役事前分布を使った解析的な学習では, データの生成過程に順序の依存性を仮定しない場合, データを逐次的に与えた場合と一度にすべて与えた場合とで最終的に得られる事後分布が一致する.

\section{マルコフ連鎖}
確率変数の系列${\bm {z^{(1)}, z^{(2)}}, \ldots}$に対して
\begin{equation}
  p(\bm {z^(t) | z^{(1)}, z^{(2)}, \ldots, z^{(t-1)}}) = p(\bm {z^{(t)} | z^{(t-1)}})
\end{equation}
が成り立つとき, 系列${\bm {z^{(1)}, z^{(2)}}, \ldots}$を{\bf 一次マルコフ連鎖(first-order Marcov chain)}と呼ぶ.
{\bf 遷移確率 (transition probability)}を${\mathcal{T} (\bm {z^{(t-1)}, z^{(t)}})}$とおく. 次の式が成り立つとき, 分布${p_\ast(\bm {z})}$は{\bf 定常分布 (statinary distribution)}であるという.
\begin{equation}
  p_\ast(\bm {z}) = \int_{}^{} \mathcal{T} (\bm {z', z})p_\ast(\bm {z'}) \,\mathrm{d}{\bm {z'}}
\end{equation}
定常状態${p_\ast(\bm {z})}$がサンプルを取り出したい事後分布だとして, ${p_\ast(\bm {z})}$に分布収束するような遷移確率${\mathcal{T} (\bm {z^{(t-1)}, z^{(t)}})}$を設計するのがマルコフ連鎖モンテカルロ法のアイデアである. ${p_\ast(\bm {z})}$が定常分布となるための十分条件として{\bf 詳細釣り合い条件 (detailed balance condition)}がある.
\begin{equation}
  p_\ast(\bm {z})\mathcal{T} (\bm {z^{(t-1)}, z^{(t)}}) =  p_\ast(\bm {z'})\mathcal{T} (\bm {z^{(t-1)}, z^{(t)}})
\end{equation}
詳細釣り合い条件に加え, サンプルサイズを無限大にしたとき, 遷移確率よって任意の初期状態${p(\bm {z_0})}$から定常分布${p_\ast(\bm {z})}$に収束できなければならない. この特性をエルゴード性と呼ぶ. 具体的には, マルコフ連鎖において任意の状態から任意の状態へ有限回数で遷移できること(既約性), すべての状態が固定の周期性をもたないこと(非周期性), さらに同じ状態に有限回で戻ることができること(正再帰性)が求められる.

\subsection{最適化に基づく推論手法}
マルコフ連鎖モンテカルロ法は, 無限に計算を続ければ得られるサンプルが真の分布から得られたものと同一視できるという理論面で優れた特性がある. しかし, 実用上は必要なサンプルサイズが明確に決めにくいことや, 計算コストが膨大になるなどの欠点をもっています. 一方で, 機械学習の分野で主流となっている方法は勾配情報を用いた数値最適化に基づく手法で, 実験的には非常に速い収束測度を持つことが示されている.
最適化による近似推論アルゴリズムの中で, 現在最も広く用いられている手法が{\bf 変分推論法 (variational inference method)}である. この方法では, 事前分布を計算する際に登場する解析不可能な積分を, 最適化の問題に置き換えることによって近似的に数値計算する. 周辺尤度${p(\bm {X})}$の計算には潜在変数${Z}$の積分除去${p(\bm {X}) = \int_{}^{} p(\bm {X, Z}) \,\mathrm{d}{\bm {Z}} }$が必要になるが, モデルが複雑になるとこの積分は解析的に解析的に実行できない. 変分推論法では, {\bf エビデンス下界 (evidence lower bound, ELBO)}と呼ばれる対数周辺尤度${\ln p(\bm {X})}$の下界${\mathcal{L} (\bm {\xi })}$を考える.
\begin{equation}
  \ln p(\bm {X}) \geq \mathcal{L}(\bm {\xi})
\end{equation}
ここで,${\bm {\xi}}${\bf 変分パラメータ (variational parameter)}と呼ばれてるもので, 変分推論報における近似分布の平均や分散などを指す. ちなみに, ELBOを負にした${\mathcal{F} = -\mathcal{L}(\bm {xi})}$は{\bf 変分エネルギー (variational energy)}と呼ばれる. 勾配降下法などの一般的な最適化手法を用いて${\mathcal{L}(\bm {\xi})}$を${\bm {\xi}}$によって最大化すれば, 対数周辺尤度${\ln p(\bm {X})}$ の近似解が得られることになる.
ELBOの設計の仕方はいくつかあり, モデルや目的に応じて使い分ける. 最もよく使われる手法は, 事後分布${p(\bm{Z|X})}$をパラメータ${\bm {\xi}}$で定められるある分布${q(\bm {Z;\xi})}$によって近似することである. 近似の良さを測る手法にもいくつかあるが, 変分推論法では次のようなKLダイバージェンスを使い, 変分パラメータ${\bm {\xi}}$に関して最小化することによって近似分布${q(\bm {Z;\xi})}$を得る.
\begin{equation}
  q(\bm {Z;\xi_{opt}}) = {\arg\min}_{\bm {opt}} D_{KL}[q(\bm {Z;\xi})||p(\bm {Z|X})]
\end{equation}
また, 対数周辺尤度${\ln p(\bm {X})}$は次のようにELBOと上式のKLダイバージェンスに分解できる.
\begin{equation}
  \ln p(\bm {X}) = \mathcal{L}(\bm {\xi}) + D_{KL}[q(\bm {Z;\xi})||p(\bm {Z|X})]
\end{equation}
ただし,
\begin{equation}
  \mathcal{L}(\bm {\xi}) = \int_{}^{} q(\bm {Z;\xi}\ln\frac{p(\bm {Z|X})}{q(\bm {Z;\xi})} \,\mathrm{d}{\bm {Z}}
\end{equation}
上式からわかるように, 対数周辺尤度${\ln p(\bm {X})}$自体は${\bm {\xi}}$の値にかかわらず一定なので,${D_{KL}[q(\bm {Z;\xi})||p(\bm {Z|X})]}$を${\bm {\xi}}$に関して最小化する問題は, ${\mathcal{L} {\bm {\xi}}}$を${\bm {\xi}}$に関して最小化する問題と等価になる. 近似分布${q}$の置き方には様々な選択があり, 潜在変数の集合${\bm {Z}}$が${\bm {Z} = \{ \bm{Z_1, \ldots, Z_M}\}}$のように${M}$個に分割できるとする. 複雑なモデルに対しては, 事前分布に独立性を仮定して近似する方法がよく使われている.
\begin{equation}
  q(\bm {Z}) = \prod_{i=1}^{M} q(\bm {Z_i})
\end{equation}
この手法は特に{\bf 平均場近似 (mean field approximation)}と呼ばれている. 平均場近似では, 各近似分布${q(\bm {Z_1}, \ldots, \bm {Z_M})}$を交互に更新していく手続きを繰り返すため, アルゴリズムの特性はギブスサンプリングと非常に似たものになっている.

\section{ニューラルネットワークのベイズ推論}
バッチ学習によるニューラルネットワーク(以下, NN)の基本的な学習方法を示す. 順伝播型NNをベイズ化する方法は, ネットワークの挙動を支配するパラメータに事前分布を設定することによって確率的な学習や予測が行えるようにするものである.
入力データ${\bm {X} = \{x_1, \ldots, x_N\}}$が与えられたもとでの, 観測データ${\bm {Y} = \{\bm {y_1, \ldots, y_N}\}}$及びパラメータの同時分布を
\begin{equation}
  p(\bm {Y, W| X}) = p(\bm {W})\prod_{n=1}^{N} p(\bm {y_n|x_n, W})
\end{equation}
とおく. ここでは, ${\bm {x_n} \in \mathbb{R}^{H_0}}$から${\bm {y_n} \in \mathbb{R}^{D}}$を予測する回帰問題であるとし, 観測モデルには次のようなガウス分布を使う.
\begin{equation}
  p(\bm {y_n | x_n, W}) = \mathcal{N} (\bm {y_n|f(X_n;W)}, \sigma_y^2 \bm {I})
\end{equation}
ここで${\sigma_y^2}$は固定のノイズパラメータで, ${\bm {f(X_n;W)}}$は出力次元が${D}$であるNNである. ベイズ推論の枠組みでは, 学習データが与えられたあとのパラメータの事後分布を計算する. したがって, NNのパラメータには事前分布を明示的に設定する必要がある. ここでは簡単のため各重みパラメータを${w \in \bm {W}}$とし, 次のような独立なガウス分布を考える.
\begin{equation}
  p(w) = \mathcal{N}(w|0, \sigma_w^2)
\end{equation}

次の図には活性化関数に双曲線正接関数, 入力ベクトルを${(x, 1)^T}$とし, 隠れ層の数${H_1}$及び重みパラメータに仮定するノイズ${\sigma_w^2}$を変えた場合の関数のサンプル例を示す. ${H_1}$が大きくなる程事前分布によって生成される関数が複雑化し, また${\sigma_w^2}$が大きくなるほど急激な変化を持つ関数が生成されていることがわかる.

\subsection{ラプラス近似による学習}
ベイズニューラルネットワーク(以下, BNN)に対するラプラス近似による学習と予測を導出する. 簡単のため, 出力次元は${D = 1}$とする. はじめにモデルの事後分布のMAP推定値を最適化により求めたあと, その周辺をガウス分布によって近似する. BNNにおいては重みパラメータ${\bm {W}}$の事後分布のMAP推定値を求めることが最初のステップになる. 事後分布は
\begin{eqnarray}
  p(\bm {W|X, Y}) &=& \frac{p(\bm {W})p(\bm {Y|X, W})}{p(\bm {Y|X})} \nonumber \\
   &\propto& p(\bm {W})p(\bm {Y|X, W})
\end{eqnarray}
と書ける. 分母には${\bm {W}}$がないので, ${\bm {W}}$の最適化の過程では無視できる.
局所最適解${\bm {W_{MAP}}}$は, 対数事後分布の勾配を利用して
\begin{equation}
  \bm {W_{new}} = \bm {W_{old}} + \alpha \nabla_{\bm {W}} \ln p(\bm {W|Y, X})|_{\bm {W = W_{old}}}
\end{equation}
のように繰り返し更新すれば求まる. ここで, ${\alpha > 0}$は学習率である. 対数事後分布は,
\begin{eqnarray}
  \ln p(\bm {W|Y, X}) &=& \ln p(\bm {W|Y, X}) + \ln p(\bm {W}) + c \nonumber \\
  &=& \sum_{n=1}^{N} \ln p(y_n|\bm {x_n, W}) + \sum_{w \in \bm {W}} \ln p(x) + c
\end{eqnarray}
と書ける. あるパラメータ${w \in \bm {W}}$の偏微分を計算すると
\begin{equation}
  \frac{\partial }{\partial w}\ln p(\bm {W|Y, X}) = - \{\frac{1}{\sigma_y^2}\frac{\partial}{\partial w}E(\bm {W}) + \frac{1}{\sigma_w^2}\frac{\partial}{\partial w}\Omega_{L2}(\bm {W})\}
\end{equation}
となる. 上式において${\Omega_{L2}(\bm {W})}$は各パラメータ${w}$に関するガウス事前分布${p(w)}$に由来するもびであるが, こちらの方が微分が容易である. また, ${E(\bm {W})}$はNNの誤差関数であるが, これは通常の誤差逆伝播を用いて微分を評価する.
\begin{equation}
  q(\bm {W}) = \mathcal{N} (\bm {W|W_{MAP}}, \{\Lambda (\bm {W_{MAP}}) \}^{-1})
\end{equation}
ここで,${Lambda}$は精度行列であり,
\begin{eqnarray}
  \Lambda &=& - \nabla _{\bm {W}}^2 \ln p(\bm {W|Y, X}) \nonumber \\
  &=& \frac{1}{\sigma_w^2}\bm {I} + \frac{1}{\sigma_y^2}\bm {H}
\end{eqnarray}
である. また, ${\bm {H}}$ はNNの誤差関数に対するヘッセ行列である.
\subsection{予測分布の近似}
パラメータの事後分布の近似を得た後は, テストの入力${\bm {x_\ast}}$に対する出力${y_\ast}$の予測分布を
\begin{equation}
  p(y_\ast|\bm {x_ast, Y, X}) \thickapprox \int_{}^{} p(y_ast | \bm {x_\ast, W})q(\bm {W}) \,\mathrm{d}{\bm {W}}
\end{equation}
として近似する. パラメータの事後分布を簡単なガウス分布${q(\bm {W})}$によって近似したものの, ${p(y_\ast|\bm {x_\ast, W})}$の中にはNNが含まれているため, 依然として一般的に予測分布の計算は解析的に行えない. ここでは予測分布を計算するために, NNの関数の線形近似を行う. この近似では, パラメータの事後分布がMAP推定値の周辺に集中しており, かつその小さな範囲においてはNNの関数値${f(\bm {x_\ast;W})}$が${\bm {W}}$の線形関数でよく近似できるという仮定をおく. テイラー展開で${\bm {W}}$の関数${f(\bm {x_\ast;W})}$を${\bm {W_{MAP}}}$まわりで一次近似すれば
\begin{equation}
  f(\bm {x_\ast;W}) \thickapprox f(\bm {x_\ast;W_{MAP}}) + \bm {g^T(W - W_{MAP})}
\end{equation}

ただし, ${\bm {g}}$は次のように関数の勾配を${\bm {W_{MAP}}}$で評価したものである.
\begin{equation}
  \bm {g} = \nabla_{\bm {W}}f(\bm {x_\ast ; W})|_{\bm {W = W_{MAP}}}
\end{equation}
この近似を用いれば, 予測分布の計算にNN特有の非線形関数がなくなるので, 解析的に計算することが可能になる. したがって, 求めたい予測分布の近似は,
\begin{eqnarray}
  p(y_\ast|\bm {x_\ast, Y, X}) &\thickapprox& \int_{}^{} p(y_\ast|\bm {x_\ast, W})q(\bm {W}) \,\mathrm{d}{\bm {W}} \nonumber \\
  &\thickapprox& \int_{}^{} \mathcal{N} (y_\ast | f(\bm {x_\ast; W_{MAP}})) + \bm {g^T (W - W_{MAP}}, \sigma_y^2) \nonumber \\
  && \mathcal{N} (\bm {W|W_{MAP}, \{ \Lambda (\bm {W_{MAP}})\}^{-1}}) \,\mathrm{d}{\bm W} \nonumber \\
  &=& \mathcal{N} (y_\ast|f(\bm {x_\ast; W_{MAP}}), \sigma^2 (\bm {x_\ast}))
\end{eqnarray}
と計算できる. ただし,
\begin{equation}
  \sigma^2(\bm {x_\ast}) = \sigma_y^2 + \bm {g^T + \{\Lambda (W_{MAP})^{-1}\}g}
\end{equation}
である.

\subsection{重みパラメータの推論}
BNNへの正規化されていない事後分布を利用すると対応するポテンシャルエネルギーは
\begin{equation}
  \mathcal{U}(\bm {W}) = - \{\ln p(\bm {Y|X, W}) + \ln p (\bm {W})\}
\end{equation}
となる. リープフロッグ法を使うためにはポテンシャルエネルギーの微分が必要になるが, 正則化項をもつ基本的なNNのコスト関数の微分と等価であるから, 誤差逆伝播による勾配計算が利用できる.

\subsection{ハイパーパラメータの推論}
重みパラメータ${\bm {W}}$の事前分布を支配する${\sigma_w^2}$や観測モデルのノイズパラメータ${\sigma_y^2}$はハイパーパラメータとして扱われ, 通常は学習を実行する前に適切なものを固定値として与えておく必要がある. これらのハイパーパラメータはデータの大まかな"スケール感"を反映していると考えられるが, もし直観的に値を指定するのが困難である場合や, 学習データに対して当てはまりの良い学習結果を得たい場合は, ハイパーパラメータに対しても事前分布を設定することによって, サンプリングの枠組みの中で重みパラメータ${\bm {W}}$と同時に推論することもできる.
ハイパーパラメータも同時推論するために, これらに事前分布を与える. パラメータ${\bm {W}}$は分散${\sigma_w^2}$をもつガウス分布にしたがって決定される. 表記を簡単にするため, 精度パラメータ${\gamma_w = \sigma_w^{-2}}$を導入し, 事前分布として,
\begin{equation}
  p(\gamma_w) = Gam (\gamma_w | a_w, b_w)
\end{equation}
を考える. ここで, ${a_w > 0, b_w > 0}$は固定値として与える. 観測ノイズに対する精度パラメータ${\gamma_y = \sigma_y^{-2}}$の事前分布も同様にして
\begin{equation}
  p(\gamma _y) = Gam (\gamma_y|a_y, b_y)
\end{equation}
と設定する. ただし, ${a_y > 0, b_y > 0}$である.
これらの精度パラメータの事前分布を導入した場合のモデルを改めて書き下すと
\begin{eqnarray}
  p(\bm {Y, W}, \gamma_w, \gamma_y | \bm {X}) &=& p(\gamma_w)p(\gamma_y)p(\bm {W} | \gamma_w) \nonumber \\
  && \prod _{n = 1}^{N} p(y_n|\bm {x_n, W}, \gamma_y)
\end{eqnarray}
となる. したがって事後分布全体は
\begin{equation}
  p(\bm {W}, \gamma_w, \gamma_y | \bm {Y, X})
\end{equation}
となる. ここではギブスサンプリングを用いて各確率変数のサンプルを得ることを考える. 各確率変数${\bm {W}, \gamma_w, \gamma_y}$を条件付き確率を用いて別々にサンプリングすることである. ${\gamma_w, \gamma_y}$がサンプルされた値で条件付けされた下での${\bm {W}}$の分布は
\begin{equation}
  p(\bm {W|Y, X}, \gamma_w, \gamma_y)
\end{equation}
となるが, これはパラメータの事後分布そのものであるため, 通常通りハミルトニアンモンテカルロ法を実行することによって${\bm {W}}$のサンプルを得る. ${\bm {W}, \gamma_y}$が与えられた下での${\gamma_w}$の分布は, ${\gamma_w}$に関わらない部分を無視すると
\begin{equation}
  p(\gamma_w| \bm {Y, X, W, \gamma_y}) \varpropto p(\bm {W}|\gamma_w)p(\gamma_w)
\end{equation}
とかける. ${p(\bm {W}|\gamma_w)}$がガウス分布であり, 精度${\gamma_w}$の事前分布${p(\gamma_w)}$には共役事前分布であるガンマ分布を用いているので, この条件付き分布もガンマ分布として解析的に以下のようにもとまる.
\begin{eqnarray}
  \gamma_w &\backsim & Gam (\hat{a_w}, \hat{b_w}) \\
  \hat{a_w} &=& a_w + \frac{K_w}{2} \\
  \hat{b_w} &=& b_w + \frac{1}{2} \sum_{w \in \bm {W}} w^2
\end{eqnarray}
のようにして${\gamma_w}$のサンプルが得られる. ただし, ${K_w}$は重みパラメータ${\bm {W}}$の総数である. 次に, ${\bm {W}, \gamma_w}$が与えらられた下での${\gamma_y}$の分布も
\begin{equation}
  p(\gamma_y|\bm {Y, X, W, \gamma_w}) \varpropto p(\gamma_y) \prod_{n=1}^{N} p(y_n|\bm {x_n, W}, \gamma_y)
\end{equation}
と計算できる. 観測モデル${p(\bm {Y|X, W, \gamma_y})}$がガウス分布であり, 精度${\gamma_y}$の事前分布${p(\gamma_y)}$には共役なガンマ分布を用いたので, こちらも解析的に分布を計算でき,
\begin{eqnarray}
  \gamma_y &=& Gam (\hat{a_y}, \hat{b_y}) \\
  \hat {a_y} &=& a_y + \frac{N}{2} \\
  \hat {b_y} &=& b_y + \frac{1}{2} \sum_{n=1}^{N} \{y_n - f(\bm {x_n;W})\}^2
\end{eqnarray}
のようにして${\gamma_y}$のサンプルが得られる. 直観的に上式を解釈すると, ${\gamma_y}$はNNの関数${f(\bm {x;W})}$で表現できない誤差を学習していると言える. ガンマ分布の平均は${\hat {a_w} / \hat {b_w}}$であるため, ${\hat {b_w}}$が大きいほど関数${f(\bm {x;W})}$による${y}$の推定の精度が低く, 観測に対する分散が大きくなるように学習される. なお, ここでは簡単のため共通なハイパーパラメータ${\gamma_w}$が与えられていると仮定したが, ハイパーパラメータを複数のグループに分割して与えることもできる.







\begin{thebibliography}{9}
  \bibitem{教科書} 斎藤康穀. ゼロから作るDeep Learning 2. p57-129
  \bibitem{Qiita} 【機械学習】誤差逆伝播法による速度改善（その2）. https://qiita.com/m-hayashi\\/items/fa4749f8080e542787d2
  \bibitem{Qiita} 【機械学習 誤差逆伝播法】word2vecメモ (1) https://qiita.com/sand/items/85ea76f9c26aabb849e7
  \bibitem{論文} Improving Distributional Similarity with Lossons Learned from Word Embeddings https://www.aclweb.org/anthology/Q15-1016/
\end{thebibliography}
\end{document}
